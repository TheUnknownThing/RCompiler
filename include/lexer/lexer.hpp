#pragma once

#include <cctype>
#include <iostream>
#include <string>
#include <string_view>
#include <unordered_map>
#include <vector>

namespace rc {

// --- GENERATED By Google Gemini ---
#define X(name, str) name,
enum class TokenType {
#include "token_defs.def"
};
#undef X

#define X(name, str)                                                           \
  case TokenType::name:                                                        \
    return str;
inline const char *toString(TokenType type) {
  switch (type) {
#include "token_defs.def"
  default:
    return "!!_UNDEFINED_TOKEN_!!";
  }
}
#undef X

inline std::ostream &operator<<(std::ostream &os, const TokenType &type) {
  os << toString(type);
  return os;
}

// --- END GENERATED By Google Gemini ---

inline const std::unordered_map<std::string_view, TokenType>
    keywordToTokenType = {
        // Strict keywords
        {"as", TokenType::AS},
        {"break", TokenType::BREAK},
        {"const", TokenType::CONST},
        {"continue", TokenType::CONTINUE},
        {"crate", TokenType::CRATE},
        {"else", TokenType::ELSE},
        {"enum", TokenType::ENUM},
        {"extern", TokenType::EXTERN},
        {"false", TokenType::FALSE},
        {"fn", TokenType::FN},
        {"for", TokenType::FOR},
        {"if", TokenType::IF},
        {"impl", TokenType::IMPL},
        {"in", TokenType::IN},
        {"let", TokenType::LET},
        {"loop", TokenType::LOOP},
        {"match", TokenType::MATCH},
        {"mod", TokenType::MOD},
        {"move", TokenType::MOVE},
        {"mut", TokenType::MUT},
        {"pub", TokenType::PUB},
        {"ref", TokenType::REF},
        {"return", TokenType::RETURN},
        {"self", TokenType::SELF},
        {"Self", TokenType::SELF_TYPE},
        {"static", TokenType::STATIC},
        {"struct", TokenType::STRUCT},
        {"super", TokenType::SUPER},
        {"trait", TokenType::TRAIT},
        {"true", TokenType::TRUE},
        {"type", TokenType::TYPE},
        {"unsafe", TokenType::UNSAFE},
        {"use", TokenType::USE},
        {"where", TokenType::WHERE},
        {"while", TokenType::WHILE},
        {"async", TokenType::ASYNC},
        {"await", TokenType::AWAIT},
        {"dyn", TokenType::DYN},

        // Reserved keywords
        {"abstract", TokenType::ABSTRACT},
        {"become", TokenType::BECOME},
        {"box", TokenType::BOX},
        {"do", TokenType::DO},
        {"final", TokenType::FINAL},
        {"macro", TokenType::MACRO},
        {"override", TokenType::OVERRIDE},
        {"priv", TokenType::PRIV},
        {"typeof", TokenType::TYPEOF},
        {"unsized", TokenType::UNSIZED},
        {"virtual", TokenType::VIRTUAL},
        {"yield", TokenType::YIELD},
        {"try", TokenType::TRY},
        {"gen", TokenType::GEN},
};

inline const std::unordered_map<std::string_view, TokenType>
    operatorToTokenType = {
        {"+", TokenType::PLUS},
        {"-", TokenType::MINUS},
        {"*", TokenType::STAR},
        {"/", TokenType::SLASH},
        {"%", TokenType::PERCENT},
        {"&", TokenType::AMPERSAND},
        {"|", TokenType::PIPE},
        {"^", TokenType::CARET},
        {"!", TokenType::NOT},
        {"?", TokenType::QUESTION},
        {"=", TokenType::ASSIGN},
        {"<", TokenType::LT},
        {">", TokenType::GT},
        {"<<", TokenType::SHL},
        {">>", TokenType::SHR},
        {"<<=", TokenType::SHL_EQ},
        {">>=", TokenType::SHR_EQ},
        {"=>", TokenType::FAT_ARROW},
        {"->", TokenType::ARROW},
        {"<=", TokenType::LE},
        {">=", TokenType::GE},
        {"==", TokenType::EQ},
        {"!=", TokenType::NE},
        {"&&", TokenType::AND},
        {"||", TokenType::OR},
        {"+=", TokenType::PLUS_EQ},
        {"-=", TokenType::MINUS_EQ},
        {"*=", TokenType::STAR_EQ},
        {"/=", TokenType::SLASH_EQ},
        {"%=", TokenType::PERCENT_EQ},
        {"&=", TokenType::AMPERSAND_EQ},
        {"|=", TokenType::PIPE_EQ},
        {"^=", TokenType::CARET_EQ},
};

inline const std::unordered_map<std::string_view, TokenType>
    punctuationToTokenType = {{"::", TokenType::COLON_COLON},
                              {"..", TokenType::DOT_DOT},
                              {"(", TokenType::L_PAREN},
                              {")", TokenType::R_PAREN},
                              {"{", TokenType::L_BRACE},
                              {"}", TokenType::R_BRACE},
                              {"[", TokenType::L_BRACKET},
                              {"]", TokenType::R_BRACKET},
                              {",", TokenType::COMMA},
                              {".", TokenType::DOT},
                              {":", TokenType::COLON},
                              {";", TokenType::SEMICOLON},
                              {"@", TokenType::AT}};

struct Token {
  TokenType type;
  std::string lexeme;
};

class Lexer {
public:
  Lexer(const std::string &source);
  std::vector<Token> tokenize();

private:
  std::string source;
  std::vector<Token> tokens;

  void firstPass();
  bool checkWordBoundary(char c);
  bool isPunctuation(char c);
  void checkForKeywords();
};

inline Lexer::Lexer(const std::string &source) : source(source) {}

inline std::vector<Token> Lexer::tokenize() {
  firstPass();
  checkForKeywords();
  return tokens;
}

inline bool Lexer::checkWordBoundary(char c) {
  if (std::isalnum(c) || c == '_') {
    return true;
  }
  return false;
}

inline bool Lexer::isPunctuation(char c) {
  return c == '(' || c == ')' || c == '{' || c == '}' || c == '[' || c == ']' ||
         c == ',' || c == '.' || c == ':' || c == ';' || c == '@';
}

inline void Lexer::firstPass() {
  auto push = [&](TokenType t, std::size_t beg, std::size_t end) {
    tokens.push_back({t, source.substr(beg, end - beg)});
  };

  std::size_t i = 0;
  const std::size_t n = source.size();

  while (i < n) {
    char c = source[i];

    if (std::isspace(static_cast<unsigned char>(c))) {
      ++i;
      continue;
    }

    // raw string
    if (i + 1 < n && (c == 'r' || (i + 2 < n && (c == 'b' || c == 'c') &&
                                   source[i + 1] == 'r'))) {
      TokenType tokenType = TokenType::STRING_LITERAL;
      size_t prefixLen = 1;

      if (c == 'b') {
        tokenType = TokenType::BYTE_STRING_LITERAL;
        prefixLen = 2;
      } else if (c == 'c') {
        tokenType = TokenType::C_STRING_LITERAL;
        prefixLen = 2;
      }

      size_t hashCount = 0;
      size_t pos = i + prefixLen;

      while (pos < n && source[pos] == '#') {
        ++hashCount;
        ++pos;
      }

      if (pos < n && source[pos] == '"') {
        std::size_t beg = i;
        i = pos + 1;

        while (i < n) {
          if (source[i] == '"') {
            bool closingMatch = true;
            for (size_t j = 0; j < hashCount; ++j) {
              if (i + 1 + j >= n || source[i + 1 + j] != '#') {
                closingMatch = false;
                break;
              }
            }

            if (closingMatch) {
              i = i + 1 + hashCount;
              push(tokenType, beg, i);
              break;
            }
          }
          ++i;
        }
        continue;
      }
    }

    if (i + 1 < n && (c == 'b' || c == 'c')) {
      char next = source[i + 1];

      if (c == 'b' && next == '\'') {
        std::size_t beg = i;
        i += 2;
        bool escaped = false;
        while (i < n) {
          char d = source[i++];
          if (!escaped && d == '\'')
            break;
          escaped = (!escaped && d == '\\');
        }
        push(TokenType::BYTE_LITERAL, beg, i);
        continue;
      }

      if (c == 'b' && next == '"') {
        std::size_t beg = i;
        i += 2;
        bool escaped = false;
        while (i < n) {
          char d = source[i++];
          if (!escaped && d == '"')
            break;
          escaped = (!escaped && d == '\\');
        }
        push(TokenType::BYTE_STRING_LITERAL, beg, i);
        continue;
      }

      if (c == 'c' && next == '"') {
        std::size_t beg = i;
        i += 2;
        bool escaped = false;
        while (i < n) {
          char d = source[i++];
          if (!escaped && d == '"')
            break;
          escaped = (!escaped && d == '\\');
        }
        push(TokenType::C_STRING_LITERAL, beg, i);
        continue;
      }
    }

    // string literal
    if (c == '"') {
      std::size_t beg = i++;
      bool escaped = false;
      while (i < n) {
        char d = source[i++];
        if (!escaped && d == '"')
          break;
        escaped = (!escaped && d == '\\');
      }
      push(TokenType::STRING_LITERAL, beg, i);
      continue;
    }

    // char literal
    if (c == '\'') {
      std::size_t beg = i++;
      bool escaped = false;
      while (i < n) {
        char d = source[i++];
        if (!escaped && d == '\'')
          break;
        escaped = (!escaped && d == '\\');
      }
      push(TokenType::CHAR_LITERAL, beg, i);
      continue;
    }

    // integer literal
    if (std::isdigit(static_cast<unsigned char>(c))) {
      std::size_t beg = i++;
      while (i < n && checkWordBoundary(source[i]))
        ++i;
      push(TokenType::INTEGER_LITERAL, beg, i);
      continue;
    }

    // identifier or keyword
    if (std::isalpha(static_cast<unsigned char>(c)) || c == '_') {
      std::size_t beg = i++;
      while (i < n && checkWordBoundary(source[i]))
        ++i;
      push(TokenType::NON_KEYWORD_IDENTIFIER, beg, i);
      continue;
    }

    // punctuation
    if (isPunctuation(c)) {
      auto it = punctuationToTokenType.find(std::string_view(&source[i], 1));
      // check for two-character punctuation
      if (i + 1 < n && isPunctuation(source[i + 1])) {
        std::string_view punct(&source[i], 2);
        auto it2 = punctuationToTokenType.find(punct);
        if (it2 != punctuationToTokenType.end()) {
          push(it2->second, i, i + 2);
          i += 2;
          continue;
        }
      }
      push(it != punctuationToTokenType.end() ? it->second : TokenType::UNKNOWN,
           i, i + 1);
      ++i;
      continue;
    }

    // operators
    bool matched = false;
    for (int len = 3; len >= 1 && !matched; --len) {
      if (i + len > n)
        continue;
      std::string_view op(&source[i], static_cast<size_t>(len));
      auto it = operatorToTokenType.find(op);
      if (it != operatorToTokenType.end()) {
        push(it->second, i, i + len);
        i += len;
        matched = true;
      }
    }
    if (matched)
      continue;

    // unknown token
    push(TokenType::UNKNOWN, i, i + 1);
    ++i;
  }
  push(TokenType::TOK_EOF, n, n);
}

inline void Lexer::checkForKeywords() {
  for (auto &tok : tokens) {
    if (tok.type == TokenType::NON_KEYWORD_IDENTIFIER) {
      auto it = keywordToTokenType.find(tok.lexeme);
      if (it != keywordToTokenType.end())
        tok.type = it->second;
    }
  }
}

} // namespace rc